---
title: "ST 563 Final Project"
author: "Jesse DeLaRosa, Grant Swigart, Yang Yue, Jenna Tan"
date: "June 30, 2020"
output: html_document
---

```{r Setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(boot)
library(randomForest)
library(caret)
library(GGally)
library(glmnet)
library(MASS)
library(class)
library(tidyverse)
library(leaps)
library(tree)
```

```{r Fileread, include=FALSE, message=FALSE, warning=FALSE}
# Jesse's file path: C:/Users/Jesse DeLaRosa/Desktop/Project/Grad School/ST 563 Statistical Learning/Final Project/winequality-red.csv
# Jenna's working directory: C:/Users/ajtan/Dropbox/2020 Summer/ST 563/Final Project/ST-563-Final-Project

setwd("C:/Users/ajtan/Dropbox/2020 Summer/ST 563/Final Project/ST-563-Final-Project")
red<-read_delim("./Wine Data-Original/winequality-red.csv",delim = ';')
```

```{r Categorization, include = TRUE}
# Creating Categorical Variables: quality2cat, quality3cat
red <- red %>% mutate("quality2cat" = factor(ifelse(quality > 0 & quality <= 5, "Low", "High")))
red <- red %>% mutate("quality3cat" = factor(ifelse(quality > 0 & quality <=3, "Low",
                                                                     ifelse(quality > 3 & quality <= 7, "Mid", "High"))))

red %>% group_by(quality3cat) %>% summarise(count = n())
red %>% group_by(quality2cat) %>% summarize(count = n())
unique(red$quality)
```

I think it's worth noting that the range of possible scores for wine quality is 1-10, however the data only reflects scores of 3-8.

The three category split of quality leads to low counts in some of the categories. Therefore, the two category split (low/high) is better as it provides a large number of counts in each category.

```{r Splitting, message=FALSE}
set.seed(30)
trainIndex <- createDataPartition(red$quality,
                                  p = .8, 
                                  list = FALSE)
red_train<-red[c(trainIndex),]
red_test<-red[-c(trainIndex),]

write_csv(red_train,"./Test and Training Data/training.csv")
write_csv(red_test,"./Test and Training Data/testing.csv")
```

```{r Plots}
red_train %>% 
  dplyr::select(c("fixed acidity","volatile acidity","citric acid","pH","quality")) %>%
  ggpairs()

red_train %>% 
  dplyr::select(c("free sulfur dioxide","total sulfur dioxide","chlorides","sulphates","quality")) %>%
  ggpairs()

red_train %>% 
  dplyr::select(c("residual sugar","alcohol","density")) %>%
  ggpairs()
```
## Regression Methods

```{r LinearReg}
# Be sure to remove the categorical variables from predictors
lm.fit = lm(quality ~.-quality2cat -quality3cat, data=red_train)
lm.pred = predict(lm.fit, red_test)
summary(lm.fit)
sum(round(lm.pred)!=red_test$quality)/nrow(red_test)
```

# obtain best subset model using cross validation (k=10)
folds = sample(1:10, nrow(red), replace=TRUE)
cv.errors = matrix(NA, 10, 11, dimnames=list(NULL, paste(1:11)))
predict.regsubsets = function(object,newdata,id,...){
form = as.formula(object$call[[2]])
mat = model.matrix(form, newdata)
coefi = coef(object, id=id)
xvars = names(coefi)
mat[,xvars]%*%coefi
}
for(j in 1:10){
best.fit = regsubsets(quality~. -quality2cat -quality3cat, data=red[folds!=j,],
nvmax=11)
for(i in 1:11){
pred = predict(best.fit, red[folds==j,], id=i)
cv.errors[j,i]= mean(red$quality[folds==j]-pred)^2)
}
}

mean.cv.errors = apply(cv.errors, 2, mean)
plot(mean.cv.errors, xlab= "Number of Predictors", ylab = "Mean CV
Error",col="red",main="Mean Cross Validation Error Rate: Best
Subset ", type="b")

# Reduce variable to 7
lm.fit1 = lm(quality ~ volatile.acidity
+chlorides+free.sulfur.dioxide+total.sulfur.dioxide+pH+
sulphates+alcohol, data=red_train)
lm.pred1 <- predict(lm.fit1, red_test type="response")
sum(round(lm.pred1)!=red_test$quality)/nrow(red_test)


```{r LogisticReg}
set.seed(1)
train.matrix=model.matrix(quality2cat~.-quality -quality3cat,data=red_train)[,-1]
test.matrix=model.matrix(quality2cat~.-quality -quality3cat,data=red_test)[,-1]

# Jenna: I'm not sure how to use the model.matrix function, so instead, I subsetted the data to the predictors/response variables we needed to perform the logistic regression
redcat_train = red_train %>% select(-c(quality,quality3cat))
redcat_test = red_test %>% select(-c(quality,quality3cat))

log.fit = glm(quality2cat~.,data=redcat_train,family=binomial)
log.probs = predict(log.fit, newdata=redcat_test, type="response")
summary(log.fit)
log.pred = rep("Low",318)
log.pred[log.probs>0.5]="High"
table(log.pred,redcat_test$quality2cat)
sum(log.pred!=redcat_test$quality2cat)/nrow(redcat_test)
```

```{r Lasso}
cv.fit1 = cv.glmnet(train.matrix, red_train$quality2cat, alpha=1, family="binomial", type.measure = "class",nfolds=10)
plot(cv.fit1)
probs = predict(cv.fit1, s="lambda.min", newx=test.matrix, type="response")
glm.pred =rep("Low", nrow(red_test))
glm.pred[probs>0.5]="High"
table(glm.pred, red_test$quality2cat)
mean((glm.pred)!=red_test$quality2cat)
```

```{r LDA}
lda.fit=lda(red_train$quality2cat~. -quality -quality3cat, data=red_train)
lda.pred=predict(lda.fit, red_test)
lda.class=lda.pred$class
table(lda.class, red_test$quality2cat)
mean(lda.class!=red_test$quality2cat)
```

```{r QDA}
qda.fit = qda(red_train$quality2cat ~. -quality -quality3cat, data=red_train)
qda.pred = predict(qda.fit, red_test)
qda.class=lda.pred$class
table(qda.class, red_test$quality2cat)
mean(qda.class!=red_test$quality2cat)
```

```{r KNN}
# Cannot get this to run? Explicitly made train.quality2cat a matrix caused code to run.
train.x <- scale(red_train[,1:11])
test.x <- scale(red_test[,1:11])
train.quality2cat <- as.matrix(red_train[,13])
knnmisclass = 1
knnvalue = 0

for (i in 1:100){
knn.pred <- knn(train.x, test.x, train.quality2cat, k=i)
check = mean(knn.pred!=red_test$quality2cat)
if (check < knnmisclass){
  knnmisclass = check
  knnvalue = i
}
}

knnmisclass
knnvalue
```
# LASSO

```{r lasso, include = TRUE}
regfit.full = regsubsets(quality ~ ., data = red_train,nvmax=11)
reg.summary = summary(regfit.full)
which.max(reg.summary$adjr2)
which.min(reg.summary$cp)
which.min(reg.summary$bic)

redpredictors <- model.matrix(quality~.-quality2cat-quality3cat,red_train)[,-1]
redpredictorstest <- model.matrix(quality~.-quality2cat-quality3cat,red_test)[,-1]
redoutcome <- red_train$quality
grid = 10^seq(10,-2,length=100)

lasso.fit <- glmnet(redpredictors, redoutcome, alpha=1,lambda=grid)
cv.out <- cv.glmnet(redpredictors,redoutcome,alpha=1)
bestlam = cv.out$lambda.min
out=glmnet(redpredictors,redoutcome,alpha=1,lamda=grid)
lass.pred=predict(out,type="response",newx=redpredictorstest, s=bestlam)
sum(round(lass.pred)!=red_test$quality)/nrow(red_test)
```
# Ridge Regression

```{r ridge, include = TRUE}
ridge.fit <- glmnet(redpredictors, redoutcome, alpha=0,lambda=grid)
cv.out <- cv.glmnet(redpredictors,redoutcome,alpha=0)
bestlam = cv.out$lambda.min
out=glmnet(redpredictors,redoutcome,alpha=0,lamda=grid)
ridge.pred=predict(out,type="response",newx=redpredictorstest, s=bestlam)
sum(round(ridge.pred)!=red_test$quality)/nrow(red_test)
```
##Classfication Method
